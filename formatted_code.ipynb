{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36d9dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, BitsAndBytesConfig, Gemma3ForCausalLM\n",
    "import torch\n",
    "\n",
    "model_id = \"google/gemma-3-270m-it\"\n",
    "quantization_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = Gemma3ForCausalLM.from_pretrained(\n",
    "    model_id\n",
    ").eval()\n",
    "\n",
    "model_8bitq = Gemma3ForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config = quantization_config\n",
    ").eval()\n",
    "\n",
    "quant_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "model_4bitq = Gemma3ForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=quant_config\n",
    ").eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68bb5b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.save_pretrained(r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\tokenizer\")\n",
    "model.save_pretrained(r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\model\")\n",
    "model_8bitq.save_pretrained(r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\model_8bitq\")\n",
    "model_4bitq.save_pretrained(r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\model_4bitq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb0675ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tensors: 236\n",
      "\n",
      "Tensor name: model.embed_tokens.weight, dtype: torch.float32, shape: torch.Size([262144, 640])\n",
      "Tensor name: model.layers.0.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.0.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.0.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.0.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.1.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.1.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.1.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.1.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.10.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.10.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.10.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.10.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.11.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.11.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.11.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.11.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.12.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.12.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.12.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.12.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.13.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.13.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.13.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.13.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.14.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.14.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.14.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.14.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.15.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.15.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.15.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.15.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.16.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.16.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.16.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.16.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.17.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.17.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.17.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.17.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.2.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.2.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.2.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.2.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.3.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.3.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.3.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.3.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.4.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.4.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.4.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.4.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.5.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.5.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.5.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.5.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.6.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.6.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.6.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.6.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.7.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.7.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.7.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.7.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.8.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.8.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.8.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.8.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.9.input_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.9.mlp.up_proj.weight, dtype: torch.float32, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.9.post_attention_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.post_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.pre_feedforward_layernorm.weight, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.self_attn.k_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.weight, dtype: torch.float32, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.9.self_attn.q_norm.weight, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.weight, dtype: torch.float32, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.weight, dtype: torch.float32, shape: torch.Size([256, 640])\n",
      "Tensor name: model.norm.weight, dtype: torch.float32, shape: torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "filename = \"C:/AI_HW/DL_PRAC/Gemma/gemma3-270m/model/model.safetensors\"\n",
    "\n",
    "with safe_open(filename, framework=\"pt\") as f:\n",
    "    keys = list(f.keys())\n",
    "    print(f\"Total number of tensors: {len(keys)}\\n\")\n",
    "    \n",
    "    for key in keys:\n",
    "        tensor = f.get_tensor(key)\n",
    "        print(f\"Tensor name: {key}, dtype: {tensor.dtype}, shape: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2140a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tensors: 488\n",
      "\n",
      "Tensor name: model.embed_tokens.weight, dtype: torch.float16, shape: torch.Size([262144, 640])\n",
      "Tensor name: model.layers.0.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.0.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.0.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.0.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.0.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.0.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.1.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.1.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.1.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.1.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.1.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.1.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.1.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.10.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.10.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.10.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.10.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.10.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.10.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.10.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.11.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.11.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.11.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.11.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.11.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.11.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.11.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.12.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.12.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.12.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.12.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.12.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.12.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.12.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.13.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.13.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.13.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.13.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.13.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.13.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.13.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.14.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.14.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.14.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.14.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.14.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.14.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.14.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.15.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.15.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.15.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.15.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.15.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.15.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.15.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.16.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.16.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.16.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.16.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.16.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.16.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.16.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.17.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.17.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.17.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.17.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.17.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.17.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.17.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.2.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.2.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.2.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.2.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.2.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.2.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.2.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.3.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.3.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.3.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.3.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.3.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.3.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.3.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.4.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.4.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.4.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.4.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.4.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.4.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.4.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.5.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.5.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.5.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.5.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.5.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.5.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.5.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.6.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.6.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.6.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.6.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.6.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.6.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.6.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.7.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.7.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.7.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.7.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.7.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.7.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.7.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.8.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.8.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.8.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.8.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.8.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.8.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.8.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.9.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "Tensor name: model.layers.9.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.9.mlp.up_proj.SCB, dtype: torch.float32, shape: torch.Size([2048])\n",
      "Tensor name: model.layers.9.mlp.up_proj.weight, dtype: torch.int8, shape: torch.Size([2048, 640])\n",
      "Tensor name: model.layers.9.mlp.up_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.9.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.weight, dtype: torch.int8, shape: torch.Size([640, 1024])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.9.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.SCB, dtype: torch.float32, shape: torch.Size([1024])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.weight, dtype: torch.int8, shape: torch.Size([1024, 640])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.SCB, dtype: torch.float32, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.weight, dtype: torch.int8, shape: torch.Size([256, 640])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "Tensor name: model.norm.weight, dtype: torch.float16, shape: torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "filename = \"C:/AI_HW/DL_PRAC/Gemma/gemma3-270m/model_8bitq/model.safetensors\"\n",
    "\n",
    "with safe_open(filename, framework=\"pt\") as f:\n",
    "    keys = list(f.keys())\n",
    "    print(f\"Total number of tensors: {len(keys)}\\n\")\n",
    "    \n",
    "    for key in keys:\n",
    "        tensor = f.get_tensor(key)\n",
    "        print(f\"Tensor name: {key}, dtype: {tensor.dtype}, shape: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6488807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tensors: 614\n",
      "\n",
      "Tensor name: model.embed_tokens.weight, dtype: torch.float16, shape: torch.Size([262144, 640])\n",
      "Tensor name: model.layers.0.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.0.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.0.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.0.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.0.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.0.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.0.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.0.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.0.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.0.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.0.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.0.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.0.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.1.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.1.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.1.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.1.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.1.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.1.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.1.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.1.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.1.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.1.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.1.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.1.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.1.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.1.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.1.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.1.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.10.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.10.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.10.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.10.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.10.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.10.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.10.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.10.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.10.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.10.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.10.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.10.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.10.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.10.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.10.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.10.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.11.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.11.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.11.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.11.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.11.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.11.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.11.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.11.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.11.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.11.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.11.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.11.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.11.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.11.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.11.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.11.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.12.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.12.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.12.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.12.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.12.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.12.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.12.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.12.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.12.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.12.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.12.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.12.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.12.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.12.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.12.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.12.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.13.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.13.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.13.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.13.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.13.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.13.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.13.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.13.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.13.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.13.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.13.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.13.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.13.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.13.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.13.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.13.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.14.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.14.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.14.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.14.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.14.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.14.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.14.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.14.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.14.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.14.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.14.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.14.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.14.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.14.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.14.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.14.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.15.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.15.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.15.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.15.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.15.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.15.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.15.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.15.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.15.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.15.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.15.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.15.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.15.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.15.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.15.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.15.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.16.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.16.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.16.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.16.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.16.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.16.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.16.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.16.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.16.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.16.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.16.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.16.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.16.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.16.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.16.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.16.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.17.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.17.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.17.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.17.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.17.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.17.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.17.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.17.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.17.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.17.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.17.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.17.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.17.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.17.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.17.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.17.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.2.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.2.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.2.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.2.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.2.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.2.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.2.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.2.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.2.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.2.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.2.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.2.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.2.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.2.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.2.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.2.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.3.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.3.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.3.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.3.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.3.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.3.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.3.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.3.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.3.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.3.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.3.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.3.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.3.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.3.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.3.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.3.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.4.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.4.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.4.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.4.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.4.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.4.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.4.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.4.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.4.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.4.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.4.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.4.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.4.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.4.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.4.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.4.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.5.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.5.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.5.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.5.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.5.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.5.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.5.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.5.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.5.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.5.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.5.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.5.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.5.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.5.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.5.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.5.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.6.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.6.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.6.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.6.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.6.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.6.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.6.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.6.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.6.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.6.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.6.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.6.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.6.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.6.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.6.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.6.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.7.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.7.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.7.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.7.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.7.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.7.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.7.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.7.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.7.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.7.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.7.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.7.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.7.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.7.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.7.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.7.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.8.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.8.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.8.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.8.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.8.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.8.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.8.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.8.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.8.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.8.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.8.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.8.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.8.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.8.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.8.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.8.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.9.input_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.mlp.down_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.9.mlp.down_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.9.mlp.down_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.9.mlp.down_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.9.mlp.gate_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.9.mlp.up_proj.weight, dtype: torch.uint8, shape: torch.Size([655360, 1])\n",
      "Tensor name: model.layers.9.mlp.up_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([20480])\n",
      "Tensor name: model.layers.9.mlp.up_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.9.mlp.up_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.9.post_attention_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.post_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.pre_feedforward_layernorm.weight, dtype: torch.float16, shape: torch.Size([640])\n",
      "Tensor name: model.layers.9.self_attn.k_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.9.self_attn.k_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.9.self_attn.o_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.9.self_attn.q_norm.weight, dtype: torch.float16, shape: torch.Size([256])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.weight, dtype: torch.uint8, shape: torch.Size([327680, 1])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([10240])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.9.self_attn.q_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([80])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.weight, dtype: torch.uint8, shape: torch.Size([81920, 1])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.weight.absmax, dtype: torch.float32, shape: torch.Size([2560])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.weight.quant_map, dtype: torch.float32, shape: torch.Size([16])\n",
      "Tensor name: model.layers.9.self_attn.v_proj.weight.quant_state.bitsandbytes__fp4, dtype: torch.uint8, shape: torch.Size([79])\n",
      "Tensor name: model.norm.weight, dtype: torch.float16, shape: torch.Size([640])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "filename = \"C:/AI_HW/DL_PRAC/Gemma/gemma3-270m/model_4bitq/model.safetensors\"\n",
    "\n",
    "with safe_open(filename, framework=\"pt\") as f:\n",
    "    keys = list(f.keys())\n",
    "    print(f\"Total number of tensors: {len(keys)}\\n\")\n",
    "    \n",
    "    for key in keys:\n",
    "        tensor = f.get_tensor(key)\n",
    "        print(f\"Tensor name: {key}, dtype: {tensor.dtype}, shape: {tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51a14749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072393732\n",
      "435927298\n",
      "385792258\n"
     ]
    }
   ],
   "source": [
    "print(model.get_memory_footprint())\n",
    "print(model_8bitq.get_memory_footprint())\n",
    "print(model_4bitq.get_memory_footprint())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a3230ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor name: model.layers.0.mlp.down_proj.weight, dtype: torch.float32, shape: torch.Size([640, 2048])\n",
      "tensor([[ 0.0026,  0.0125, -0.0148,  ..., -0.0024,  0.0369,  0.0162],\n",
      "        [-0.0032, -0.0031, -0.0146,  ..., -0.0066, -0.0359, -0.0045],\n",
      "        [-0.0388, -0.0079, -0.0167,  ...,  0.0097,  0.0054,  0.0496],\n",
      "        ...,\n",
      "        [-0.0220,  0.0062, -0.0018,  ..., -0.0095,  0.0047, -0.0020],\n",
      "        [ 0.0148,  0.0131, -0.0320,  ...,  0.0036,  0.0080, -0.0043],\n",
      "        [ 0.0020, -0.0002,  0.0069,  ...,  0.0118,  0.0067, -0.0120]])\n",
      "First 10 values: tensor([ 0.0026,  0.0125, -0.0148,  0.0182,  0.0282, -0.0091,  0.0188, -0.0004,\n",
      "        -0.0233, -0.0071])\n"
     ]
    }
   ],
   "source": [
    "# Print the values of a specific tensor from safetensors file\n",
    "from safetensors import safe_open\n",
    "\n",
    "filename = \"C:/AI_HW/DL_PRAC/Gemma/gemma3-270m/model/model.safetensors\"\n",
    "tensor_key = \"model.layers.0.mlp.down_proj.weight\"\n",
    "\n",
    "with safe_open(filename, framework=\"pt\") as f:\n",
    "    tensor = f.get_tensor(tensor_key)\n",
    "    print(f\"Tensor name: {tensor_key}, dtype: {tensor.dtype}, shape: {tensor.shape}\")\n",
    "    print(tensor)  # Print all values (may be large)\n",
    "    # Optionally, print only some elements\n",
    "    print(\"First 10 values:\", tensor.flatten()[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ac1a332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor name: model.layers.0.mlp.down_proj.SCB, dtype: torch.float32, shape: torch.Size([640])\n",
      "First 10 values: [0.076171875, 0.08642578125, 0.08154296875, 0.0849609375, 0.10302734375, 0.0810546875, 0.09033203125, 0.08642578125, 0.087890625, 0.09912109375]\n",
      "----------------------------------------\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight, dtype: torch.int8, shape: torch.Size([640, 2048])\n",
      "First 10 values: [4, 21, -25, 30, 47, -15, 31, -1, -39, -12]\n",
      "----------------------------------------\n",
      "Tensor name: model.layers.0.mlp.down_proj.weight_format, dtype: torch.uint8, shape: torch.Size([])\n",
      "First 10 values: 0\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "filename = \"C:/AI_HW/DL_PRAC/Gemma/gemma3-270m/model_8bitq/model.safetensors\"\n",
    "tensor_keys = [\n",
    "    \"model.layers.0.mlp.down_proj.SCB\",\n",
    "    \"model.layers.0.mlp.down_proj.weight\",\n",
    "    \"model.layers.0.mlp.down_proj.weight_format\"\n",
    "]\n",
    "\n",
    "with safe_open(filename, framework=\"pt\") as f:\n",
    "    for key in tensor_keys:\n",
    "        tensor = f.get_tensor(key)\n",
    "        print(f\"Tensor name: {key}, dtype: {tensor.dtype}, shape: {tensor.shape}\")\n",
    "        print(\"First 10 values:\", tensor.flatten()[:10].tolist() if tensor.numel() > 10 else tensor.tolist())\n",
    "        print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd3adf3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: torch.Size([640, 2048])\n",
      "mean abs diff: 0.00017775085871107876\n",
      "max abs diff: 0.002891242504119873\n",
      "first 10 dequantized: tensor([ 0.0024,  0.0126, -0.0150,  0.0180,  0.0282, -0.0090,  0.0186, -0.0006,\n",
      "        -0.0234, -0.0072])\n",
      "first 10 fp32:        tensor([ 0.0026,  0.0125, -0.0148,  0.0182,  0.0282, -0.0091,  0.0188, -0.0004,\n",
      "        -0.0233, -0.0071])\n",
      "torch.Size([640])\n",
      "torch.Size([640, 2048])\n"
     ]
    }
   ],
   "source": [
    "from safetensors import safe_open\n",
    "\n",
    "model_dir = \"C:/AI_HW/DL_PRAC/Gemma/gemma3-270m/model/model.safetensors\"\n",
    "quant_model_dir = \"C:/AI_HW/DL_PRAC/Gemma/gemma3-270m/model_8bitq/model.safetensors\"\n",
    "\n",
    "key = \"model.layers.0.mlp.down_proj.weight\"\n",
    "with safe_open(model_dir, framework =\"pt\") as f :\n",
    "    w_fp32 = f.get_tensor(key).float()\n",
    "\n",
    "with safe_open(quant_model_dir, framework = \"pt\") as f :\n",
    "    w_q = f.get_tensor(key).to(torch.int8)\n",
    "    scb = f.get_tensor(key.replace(\"weight\", \"SCB\")).float()\n",
    "    fmt = int(f.get_tensor(key.replace(\"weight\", \"weight_format\")).item())\n",
    "\n",
    "assert fmt == 0, \"This snippet assumes weight_format == 0 (symmetric per-row).\"\n",
    "\n",
    "scale = scb / 127.0  # per-row scale\n",
    "w_deq = w_q.float() * scale[:, None]\n",
    "\n",
    "diff = (w_deq - w_fp32).abs()\n",
    "print(\"shape:\", w_fp32.shape)\n",
    "print(\"mean abs diff:\", diff.mean().item())\n",
    "print(\"max abs diff:\", diff.max().item())\n",
    "print(\"first 10 dequantized:\", w_deq.flatten()[:10])\n",
    "print(\"first 10 fp32:       \", w_fp32.flatten()[:10])\n",
    "\n",
    "\n",
    "#there is a scale for each column of the tensor : \n",
    "print(scb.shape) \n",
    "print(w_q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "15b3d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 model output:  Once upon a time, there was a small, unassuming house. It was built of weathered wood, with a single, large window that offered a view of the sprawling garden. The house was filled with the scent of freshly cut grass and the gentle hum of bees. It was a place of quiet contemplation and peaceful enjoyment.\n",
      "\n",
      "The house was a haven for many people, and it was a place where they could relax and enjoy the simple pleasures of life.\n",
      "\n",
      "The house was a symbol of a bygone era, a place\n",
      "FP32 inference time (s): 11.5597\n",
      "\n",
      "8-bit model output:  Once upon a time\n",
      "8-bit (quantized) inference time (s): 25.2323\n",
      "\n",
      "(Speedup ratio: FP32 / 8-bit = 0.46)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "\n",
    "prompt = \"Once upon a time\"\n",
    "max_new_tokens = 100\n",
    "\n",
    "# Tokenize prompt with attention mask and set pad token\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True)\n",
    "input_ids = inputs[\"input_ids\"].to(\"cpu\")\n",
    "attention_mask = inputs[\"attention_mask\"].to(\"cpu\")\n",
    "\n",
    "# Make sure everything runs on CPU\n",
    "model = model.to(\"cpu\")\n",
    "model_8bitq = model_8bitq\n",
    "\n",
    "# Optionally clear unsupported generation flags for Gemma3\n",
    "try:\n",
    "    model.generation_config.top_p = None\n",
    "    model.generation_config.top_k = None\n",
    "    model_8bitq.generation_config.top_p = None\n",
    "    model_8bitq.generation_config.top_k = None\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Warm-up to populate caches\n",
    "with torch.inference_mode():\n",
    "    _ = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=1,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    _ = model_8bitq.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=1,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "# FP32 timing\n",
    "with torch.inference_mode():\n",
    "    start_fp32 = time.time()\n",
    "    output_fp32 = model.generate(\n",
    "        input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    end_fp32 = time.time()\n",
    "\n",
    "# 8-bit model timing\n",
    "with torch.inference_mode():\n",
    "    start_8bit = time.time()\n",
    "    output_8bitq = model_8bitq.generate(\n",
    "    input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_new_tokens=max_new_tokens,\n",
    "    do_sample=False,              # or True, either way EOS is banned\n",
    "    bad_words_ids=[[tokenizer.eos_token_id]],  # ban EOS token\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    end_8bit = time.time()\n",
    "\n",
    "print(\"FP32 model output: \", tokenizer.decode(output_fp32[0], skip_special_tokens=True))\n",
    "print(f\"FP32 inference time (s): {end_fp32 - start_fp32:.4f}\")\n",
    "\n",
    "print(\"\\n8-bit model output: \", tokenizer.decode(output_8bitq[0], skip_special_tokens=True))\n",
    "print(f\"8-bit (quantized) inference time (s): {end_8bit - start_8bit:.4f}\")\n",
    "\n",
    "# Report relative speed\n",
    "if (end_8bit - start_8bit) > 0:\n",
    "    speedup = (end_fp32 - start_fp32) / (end_8bit - start_8bit)\n",
    "    print(f\"\\n(Speedup ratio: FP32 / 8-bit = {speedup:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed3173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # No Real 8-bit Inference Support on CPU\n",
    "# bitsandbytes is mainly designed for use with NVIDIA GPUs, and its quantized kernels (8-bit and 4-bit) are only fast/accurate on CUDA devices.\n",
    "# On CPU, bitsandbytes can still quantize and dequantize tensors, so you can store and load int8 weightsbut it does NOT have efficient, native int8 matrix multiplication for inference.\n",
    "# Instead, it falls back to internal reconstruction and/or PyTorch logic, which is not optimized and may even process data incorrectly (typically slower, but sometimes incorrect bias or matmul implementations for quantized tensors on CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "91966e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate to French: 'How are you today?'\n",
      "\n",
      "**Translation:**\n",
      "\n",
      "*   **Option 1 (Most common):**  \"Comment allez-vous aujourd'hui ?\"\n",
      "*   **Option 2 (More formal):** \"Comment allez-vous aujourd'hui ?\"\n",
      "*   **Option 3 (More casual):** \"Comment allez-vous\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Translate to French: 'How are you today?'\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "with torch.inference_mode():\n",
    "    out = model.generate(**inputs, max_new_tokens=64, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "20953b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "Translate to Spanish: 'I love machine learning.'\n",
      "model\n",
      "The translation of \"I love machine learning\" is:\n",
      "\n",
      "* **Me encanta el aprendizaje automtico.**\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\":\"user\",\"content\":\"Translate to Spanish: 'I love machine learning.'\"}]\n",
    "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "with torch.inference_mode():\n",
    "    out = model.generate(**inputs, max_new_tokens=64, do_sample=False, pad_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.decode(out[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8399aa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "from collections import defaultdict\n",
    "from typing import Dict, Tuple\n",
    "from scipy.stats import entropy\n",
    "\n",
    "# ---------- Loading helpers ----------\n",
    "def load_safetensors_to_dict(path: str) -> Dict[str, torch.Tensor]:\n",
    "    d = {}\n",
    "    with safe_open(path, framework=\"pt\") as f:\n",
    "        keys = list(f.keys())\n",
    "        for k in keys:\n",
    "            t = f.get_tensor(k).detach().cpu()\n",
    "\n",
    "            # If this is a BitsAndBytes int8 weight with SCB and weight_format metadata,\n",
    "            # dequantize to float for fair comparisons.\n",
    "            if t.dtype == torch.int8 and k.endswith(\".weight\"):\n",
    "                scb_key = k.replace(\".weight\", \".SCB\")\n",
    "                fmt_key = k.replace(\".weight\", \".weight_format\")\n",
    "                if scb_key in keys and fmt_key in keys:\n",
    "                    scb = f.get_tensor(scb_key).detach().cpu().float()\n",
    "                    fmt = int(f.get_tensor(fmt_key).item())\n",
    "                    # format 0 = symmetric per-row scaling (scale per output channel)\n",
    "                    if fmt == 0 and scb.dim() == 1 and scb.shape[0] == t.shape[0]:\n",
    "                        scale = scb / 127.0\n",
    "                        t = t.float() * scale[:, None]\n",
    "                    else:\n",
    "                        # Unknown/unsupported format; at least cast to float to avoid overflow in metrics\n",
    "                        t = t.float()\n",
    "                else:\n",
    "                    # No SCB metadata found; cast to float so comparisons don't overflow\n",
    "                    t = t.float()\n",
    "\n",
    "            d[k] = t\n",
    "    return d\n",
    "\n",
    "def load_torch_state_dict(path: str) -> Dict[str, torch.Tensor]:\n",
    "    sd = torch.load(path, map_location='cpu')\n",
    "    # if checkpoint has 'state_dict' key (common), unwrap\n",
    "    if isinstance(sd, dict) and \"state_dict\" in sd:\n",
    "        sd = sd[\"state_dict\"]\n",
    "    return {k: v.detach().cpu() for k, v in sd.items()}\n",
    "\n",
    "# ---------- Comparison metrics ----------\n",
    "def tensor_stats(a: torch.Tensor):\n",
    "    a_np = a.numpy().ravel()\n",
    "    return {\n",
    "        \"mean\": float(a_np.mean()),\n",
    "        \"std\": float(a_np.std()),\n",
    "        \"min\": float(a_np.min()),\n",
    "        \"max\": float(a_np.max()),\n",
    "        \"abs_mean\": float(np.abs(a_np).mean())\n",
    "    }\n",
    "\n",
    "def compare_tensors(a: torch.Tensor, b: torch.Tensor, hist_bins=200) -> Dict:\n",
    "    # assume shapes equal (if not, skip)\n",
    "    a_np = a.numpy().ravel()\n",
    "    b_np = b.numpy().ravel()\n",
    "    l2 = float(np.linalg.norm(a_np - b_np))\n",
    "    rel_l2 = l2 / (float(np.linalg.norm(a_np)) + 1e-12)\n",
    "    max_abs = float(np.max(np.abs(a_np - b_np)))\n",
    "    if np.linalg.norm(a_np) < 1e-12 or np.linalg.norm(b_np) < 1e-12:\n",
    "        cosine_sim = 1.0 if np.allclose(a_np, b_np) else 0.0\n",
    "    else:\n",
    "        cosine_sim = float(np.dot(a_np, b_np) / (np.linalg.norm(a_np) * np.linalg.norm(b_np) + 1e-12))\n",
    "\n",
    "    # histogram KL (discretize)\n",
    "    # create shared bin edges covering both\n",
    "    mn = min(a_np.min(), b_np.min())\n",
    "    mx = max(a_np.max(), b_np.max())\n",
    "    if mn == mx:\n",
    "        kl = 0.0\n",
    "    else:\n",
    "        bins = np.linspace(mn, mx, hist_bins)\n",
    "        ha, _ = np.histogram(a_np, bins=bins, density=True)\n",
    "        hb, _ = np.histogram(b_np, bins=bins, density=True)\n",
    "        # add small epsilon to avoid zeros\n",
    "        ha += 1e-12\n",
    "        hb += 1e-12\n",
    "        kl = float(entropy(ha, hb))\n",
    "    return {\n",
    "        \"l2\": l2,\n",
    "        \"rel_l2\": rel_l2,\n",
    "        \"max_abs\": max_abs,\n",
    "        \"cosine\": cosine_sim,\n",
    "        \"kl_hist\": kl,\n",
    "        \"a_stats\": tensor_stats(a),\n",
    "        \"b_stats\": tensor_stats(b),\n",
    "    }\n",
    "\n",
    "# ---------- Layer-type heuristic ----------\n",
    "def layer_type_from_name(name: str) -> str:\n",
    "    # heuristic mapping for HF-like names. Update for your model naming scheme.\n",
    "    lname = name.lower()\n",
    "    if \"attn\" in lname or \"attention\" in lname or \".q_\" in lname or \".k_\" in lname or \".v_\" in lname:\n",
    "        return \"attention\"\n",
    "    if \"mlp\" in lname or \"feed_forward\" in lname or \"ffn\" in lname or \".fc\" in lname or \"dense\" in lname:\n",
    "        return \"feedforward\"\n",
    "    if \"layernorm\" in lname or \"ln\" in lname:\n",
    "        return \"layernorm\"\n",
    "    if \"embed\" in lname or \"token\" in lname:\n",
    "        return \"embedding\"\n",
    "    return \"other\"\n",
    "\n",
    "# ---------- Main comparison function ----------\n",
    "def compare_state_dicts(dict_a: Dict[str, torch.Tensor], dict_b: Dict[str, torch.Tensor]):\n",
    "    results = {}\n",
    "    for k, a in dict_a.items():\n",
    "        if k not in dict_b:\n",
    "            continue\n",
    "        b = dict_b[k]\n",
    "        if a.shape != b.shape:\n",
    "            # skip incompatible shapes (e.g., quantized packs weights differently).\n",
    "            continue\n",
    "        cmp = compare_tensors(a, b)\n",
    "        cmp[\"name\"] = k\n",
    "        cmp[\"shape\"] = tuple(a.shape)\n",
    "        cmp[\"layer_type\"] = layer_type_from_name(k)\n",
    "        results[k] = cmp\n",
    "    return results\n",
    "\n",
    "# ---------- Aggregation and reporting ----------\n",
    "def report_top_changes(results: Dict[str, Dict], top_k=25):\n",
    "    # Sort by rel_l2 or max_abs etc. Use multiple sorts for insight.\n",
    "    items = list(results.values())\n",
    "    by_rel = sorted(items, key=lambda x: x[\"rel_l2\"], reverse=True)\n",
    "    by_l2 = sorted(items, key=lambda x: x[\"l2\"], reverse=True)\n",
    "    by_max = sorted(items, key=lambda x: x[\"max_abs\"], reverse=True)\n",
    "    return {\"by_rel_l2\": by_rel[:top_k], \"by_l2\": by_l2[:top_k], \"by_max_abs\": by_max[:top_k]}\n",
    "\n",
    "def aggregate_by_type(results: Dict[str, Dict]):\n",
    "    agg = defaultdict(list)\n",
    "    for v in results.values():\n",
    "        agg[v[\"layer_type\"]].append(v)\n",
    "    summary = {}\n",
    "    for t, arr in agg.items():\n",
    "        summary[t] = {\n",
    "            \"count\": len(arr),\n",
    "            \"avg_rel_l2\": float(np.mean([x[\"rel_l2\"] for x in arr])),\n",
    "            \"avg_l2\": float(np.mean([x[\"l2\"] for x in arr])),\n",
    "            \"avg_max_abs\": float(np.mean([x[\"max_abs\"] for x in arr]))\n",
    "        }\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c525cc77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\AI_HW\\DL_PRAC\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2792: RuntimeWarning: overflow encountered in dot\n",
      "  sqnorm = x.dot(x)\n",
      "c:\\AI_HW\\DL_PRAC\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:204: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)\n",
      "c:\\AI_HW\\DL_PRAC\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:193: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n",
      "c:\\AI_HW\\DL_PRAC\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:170: RuntimeWarning: overflow encountered in reduce\n",
      "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top changed by relative L2:\n",
      "model.layers.5.self_attn.k_proj.weight                                                                                   | type=attention    | rel_l2=1.3996e-02 | l2=2.2321e-01 | max_abs=2.3953e-03\n",
      "model.layers.12.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=1.2688e-02 | l2=2.8729e-01 | max_abs=1.6186e-03\n",
      "model.layers.5.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.2564e-02 | l2=3.1157e-01 | max_abs=2.9028e-03\n",
      "model.layers.9.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.2275e-02 | l2=2.5936e-01 | max_abs=1.4745e-03\n",
      "model.layers.6.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.1991e-02 | l2=2.0512e-01 | max_abs=1.4423e-03\n",
      "model.layers.11.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=1.1782e-02 | l2=2.4195e-01 | max_abs=1.5196e-03\n",
      "model.layers.7.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.1609e-02 | l2=2.2215e-01 | max_abs=1.4379e-03\n",
      "model.layers.12.self_attn.v_proj.weight                                                                                  | type=attention    | rel_l2=1.1598e-02 | l2=1.8557e-01 | max_abs=1.3034e-03\n",
      "model.layers.10.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=1.1589e-02 | l2=1.8051e-01 | max_abs=9.7272e-04\n",
      "model.layers.3.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.1498e-02 | l2=1.8263e-01 | max_abs=1.0611e-03\n",
      "model.layers.8.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.1371e-02 | l2=1.6870e-01 | max_abs=9.4965e-04\n",
      "model.layers.4.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.1298e-02 | l2=1.5724e-01 | max_abs=8.4969e-04\n",
      "model.layers.11.self_attn.k_proj.weight                                                                                  | type=attention    | rel_l2=1.1273e-02 | l2=1.7938e-01 | max_abs=1.6513e-03\n",
      "model.layers.11.self_attn.v_proj.weight                                                                                  | type=attention    | rel_l2=1.1175e-02 | l2=1.7860e-01 | max_abs=1.2140e-03\n",
      "model.layers.17.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=1.0908e-02 | l2=1.9921e-01 | max_abs=1.0914e-03\n",
      "model.layers.7.self_attn.o_proj.weight                                                                                   | type=attention    | rel_l2=1.0803e-02 | l2=2.6609e-01 | max_abs=2.4145e-03\n",
      "model.layers.13.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=1.0330e-02 | l2=1.7121e-01 | max_abs=1.4283e-03\n",
      "model.layers.5.self_attn.o_proj.weight                                                                                   | type=attention    | rel_l2=1.0284e-02 | l2=2.5532e-01 | max_abs=2.4616e-03\n",
      "model.layers.11.self_attn.o_proj.weight                                                                                  | type=attention    | rel_l2=1.0222e-02 | l2=3.1412e-01 | max_abs=3.9062e-03\n",
      "model.layers.12.self_attn.o_proj.weight                                                                                  | type=attention    | rel_l2=1.0170e-02 | l2=2.7529e-01 | max_abs=3.9370e-03\n",
      "model.layers.0.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=1.0126e-02 | l2=2.4933e-01 | max_abs=2.8912e-03\n",
      "model.layers.16.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=1.0076e-02 | l2=1.9892e-01 | max_abs=1.9989e-03\n",
      "model.layers.13.self_attn.k_proj.weight                                                                                  | type=attention    | rel_l2=1.0035e-02 | l2=1.5989e-01 | max_abs=1.6354e-03\n",
      "model.layers.0.self_attn.o_proj.weight                                                                                   | type=attention    | rel_l2=1.0003e-02 | l2=2.9937e-01 | max_abs=2.2146e-03\n",
      "model.layers.4.self_attn.o_proj.weight                                                                                   | type=attention    | rel_l2=9.9010e-03 | l2=1.7015e-01 | max_abs=1.3740e-03\n",
      "model.layers.15.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=9.8425e-03 | l2=1.8060e-01 | max_abs=1.4882e-03\n",
      "model.layers.14.mlp.down_proj.weight                                                                                     | type=feedforward  | rel_l2=9.7168e-03 | l2=1.4961e-01 | max_abs=9.5157e-04\n",
      "model.layers.17.self_attn.o_proj.weight                                                                                  | type=attention    | rel_l2=9.7110e-03 | l2=2.3793e-01 | max_abs=3.9058e-03\n",
      "model.layers.1.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=9.7108e-03 | l2=1.5115e-01 | max_abs=1.0842e-03\n",
      "model.layers.2.mlp.down_proj.weight                                                                                      | type=feedforward  | rel_l2=9.6754e-03 | l2=1.7944e-01 | max_abs=1.4994e-03\n",
      "model.layers.13.self_attn.o_proj.weight                                                                                  | type=attention    | rel_l2=9.5883e-03 | l2=2.0911e-01 | max_abs=1.4918e-03\n",
      "model.layers.11.mlp.gate_proj.weight                                                                                     | type=feedforward  | rel_l2=9.5456e-03 | l2=4.2741e-01 | max_abs=3.1959e-03\n",
      "model.layers.17.self_attn.k_proj.weight                                                                                  | type=attention    | rel_l2=9.5394e-03 | l2=1.5182e-01 | max_abs=1.3457e-03\n",
      "model.layers.13.self_attn.v_proj.weight                                                                                  | type=attention    | rel_l2=9.5268e-03 | l2=1.5221e-01 | max_abs=1.6977e-03\n",
      "model.layers.10.mlp.gate_proj.weight                                                                                     | type=feedforward  | rel_l2=9.4700e-03 | l2=4.2468e-01 | max_abs=3.5160e-03\n",
      "model.layers.3.self_attn.o_proj.weight                                                                                   | type=attention    | rel_l2=9.3500e-03 | l2=1.5032e-01 | max_abs=1.7148e-03\n",
      "model.layers.3.self_attn.k_proj.weight                                                                                   | type=attention    | rel_l2=9.3450e-03 | l2=1.4838e-01 | max_abs=1.1837e-03\n",
      "model.layers.1.self_attn.q_proj.weight                                                                                   | type=attention    | rel_l2=9.3439e-03 | l2=2.9513e-01 | max_abs=6.3592e-03\n",
      "model.layers.12.mlp.gate_proj.weight                                                                                     | type=feedforward  | rel_l2=9.3200e-03 | l2=4.1730e-01 | max_abs=3.3622e-03\n",
      "model.layers.9.self_attn.o_proj.weight                                                                                   | type=attention    | rel_l2=9.3091e-03 | l2=2.4904e-01 | max_abs=2.4453e-03\n",
      "\n",
      "Aggregate by layer type:\n",
      "embedding    | count=  1 | avg_rel_l2=6.6679e-09 | avg_max=2.9802e-08\n",
      "layernorm    | count= 54 | avg_rel_l2=0.0000e+00 | avg_max=0.0000e+00\n",
      "feedforward  | count= 54 | avg_rel_l2=9.4924e-03 | avg_max=2.3764e-03\n",
      "attention    | count=126 | avg_rel_l2=5.1641e-03 | avg_max=1.1278e-03\n",
      "other        | count=  1 | avg_rel_l2=0.0000e+00 | avg_max=0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# example: replace these with your actual file paths or state_dicts\n",
    "orig_path = r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\model\\model.safetensors\"   # FP16/FP32\n",
    "quant_path = r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\model_8bitq\\model.safetensors\" # 8-bit/4-bit safetensors\n",
    "\n",
    "orig = load_safetensors_to_dict(orig_path)\n",
    "quant = load_safetensors_to_dict(quant_path)\n",
    "\n",
    "res = compare_state_dicts(orig, quant)\n",
    "top = report_top_changes(res, top_k=40)\n",
    "agg = aggregate_by_type(res)\n",
    "\n",
    "# print top changed layers by relative L2\n",
    "print(\"Top changed by relative L2:\")\n",
    "for r in top[\"by_rel_l2\"]:\n",
    "    print(f\"{r['name'][:120]:120} | type={r['layer_type']:12} | rel_l2={r['rel_l2']:.4e} | l2={r['l2']:.4e} | max_abs={r['max_abs']:.4e}\")\n",
    "\n",
    "print(\"\\nAggregate by layer type:\")\n",
    "for t, s in agg.items():\n",
    "    print(f\"{t:12} | count={s['count']:3} | avg_rel_l2={s['avg_rel_l2']:.4e} | avg_max={s['avg_max_abs']:.4e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98483cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int8+SCB weights found in quant checkpoint: 126\n",
      "All int8+SCB weights are dequantized to float in-memory.\n",
      "Total comparable tensors: 236\n",
      "Top-5 by rel_l2:\n",
      "model.layers.5.self_attn.k_proj.weight                                           rel_l2=1.400e-02 max_abs=2.395e-03 cosine=0.999903\n",
      "model.layers.12.mlp.down_proj.weight                                             rel_l2=1.269e-02 max_abs=1.619e-03 cosine=0.999904\n",
      "model.layers.5.mlp.down_proj.weight                                              rel_l2=1.256e-02 max_abs=2.903e-03 cosine=0.999902\n",
      "model.layers.9.mlp.down_proj.weight                                              rel_l2=1.228e-02 max_abs=1.474e-03 cosine=0.999908\n",
      "model.layers.6.mlp.down_proj.weight                                              rel_l2=1.199e-02 max_abs=1.442e-03 cosine=0.999918\n",
      "Int8 group: count=126, mean=9.232e-03, max=1.400e-02\n",
      "Others:    count=110, mean=6.062e-11, max=6.668e-09\n",
      "Manual-vs-loader dequant check for model.layers.0.mlp.down_proj.weight:\n",
      " max_abs_diff=0.000e+00 mean_abs_diff=0.000e+00\n"
     ]
    }
   ],
   "source": [
    "# Verification: ensure all int8 weights are dequantized and errors computed correctly\n",
    "import torch\n",
    "from safetensors import safe_open\n",
    "\n",
    "# Paths used above\n",
    "orig_path = r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\model\\model.safetensors\"\n",
    "quant_path = r\"C:\\AI_HW\\DL_PRAC\\Gemma\\gemma3-270m\\model_8bitq\\model.safetensors\"\n",
    "\n",
    "# 1) Identify int8 weights with SCB metadata in the quant checkpoint\n",
    "with safe_open(quant_path, framework=\"pt\") as fq:\n",
    "    q_keys = list(fq.keys())\n",
    "    int8_weight_keys = []\n",
    "    for k in q_keys:\n",
    "        if k.endswith(\".weight\"):\n",
    "            t = fq.get_tensor(k)\n",
    "            if t.dtype == torch.int8 and k.replace(\".weight\", \".SCB\") in q_keys:\n",
    "                int8_weight_keys.append(k)\n",
    "\n",
    "print(f\"Int8+SCB weights found in quant checkpoint: {len(int8_weight_keys)}\")\n",
    "\n",
    "# 2) Load dicts via our loader (which dequantizes int8 with SCB format=0)\n",
    "orig = load_safetensors_to_dict(orig_path)\n",
    "quant = load_safetensors_to_dict(quant_path)\n",
    "\n",
    "# Assert: all int8+SCB weight tensors should now be float in 'quant'\n",
    "remaining_int8 = [k for k in int8_weight_keys if isinstance(quant.get(k, None), torch.Tensor) and quant[k].dtype == torch.int8]\n",
    "if remaining_int8:\n",
    "    print(\"[WARN] Some int8+SCB weights were not dequantized:\")\n",
    "    for k in remaining_int8[:20]:\n",
    "        print(\" -\", k)\n",
    "else:\n",
    "    print(\"All int8+SCB weights are dequantized to float in-memory.\")\n",
    "\n",
    "# 3) Compute comparisons and summarize by layer groups\n",
    "results = compare_state_dicts(orig, quant)\n",
    "print(f\"Total comparable tensors: {len(results)}\")\n",
    "\n",
    "# Overall top-5 by rel_l2\n",
    "items = sorted(results.values(), key=lambda x: x[\"rel_l2\"], reverse=True)\n",
    "print(\"Top-5 by rel_l2:\")\n",
    "for r in items[:5]:\n",
    "    print(f\"{r['name']:80} rel_l2={r['rel_l2']:.3e} max_abs={r['max_abs']:.3e} cosine={r['cosine']:.6f}\")\n",
    "\n",
    "# 4) Report stats focused on previously-int8 tensors vs the rest\n",
    "int8_names = set(int8_weight_keys)\n",
    "rel_l2_int8 = [v[\"rel_l2\"] for k,v in results.items() if k in int8_names]\n",
    "rel_l2_other = [v[\"rel_l2\"] for k,v in results.items() if k not in int8_names]\n",
    "\n",
    "if rel_l2_int8:\n",
    "    print(f\"Int8 group: count={len(rel_l2_int8)}, mean={float(sum(rel_l2_int8)/len(rel_l2_int8)):.3e}, max={float(max(rel_l2_int8)):.3e}\")\n",
    "else:\n",
    "    print(\"Int8 group: count=0 (no comparable int8 weights)\")\n",
    "\n",
    "if rel_l2_other:\n",
    "    print(f\"Others:    count={len(rel_l2_other)}, mean={float(sum(rel_l2_other)/len(rel_l2_other)):.3e}, max={float(max(rel_l2_other)):.3e}\")\n",
    "else:\n",
    "    print(\"Others:    count=0\")\n",
    "\n",
    "# 5) Spot-check: manual dequant of a sample key and compare to loader output\n",
    "sample = None\n",
    "for k in int8_weight_keys:\n",
    "    if k in quant and k in orig and orig[k].shape == quant[k].shape:\n",
    "        sample = k\n",
    "        break\n",
    "\n",
    "if sample is not None:\n",
    "    with safe_open(quant_path, framework=\"pt\") as fq:\n",
    "        w_q = fq.get_tensor(sample).to(torch.int8)\n",
    "        scb = fq.get_tensor(sample.replace(\".weight\", \".SCB\")).float()\n",
    "        fmt = int(fq.get_tensor(sample.replace(\".weight\", \".weight_format\")).item())\n",
    "    if fmt == 0 and scb.dim() == 1 and scb.shape[0] == w_q.shape[0]:\n",
    "        w_deq_manual = w_q.float() * (scb / 127.0)[:, None]\n",
    "        w_deq_loader = quant[sample]\n",
    "        dd = (w_deq_manual - w_deq_loader).abs()\n",
    "        print(f\"Manual-vs-loader dequant check for {sample}:\")\n",
    "        print(f\" max_abs_diff={dd.max().item():.3e} mean_abs_diff={dd.mean().item():.3e}\")\n",
    "    else:\n",
    "        print(f\"Sample {sample} has unsupported format={fmt}; skipped manual check\")\n",
    "else:\n",
    "    print(\"No suitable int8 sample found for manual check.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40899d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
