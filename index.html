<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kommalapati Lahari</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&family=Playfair+Display:ital,wght@0,400;0,700;1,400&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <header>
            <h1 class="name">Kommalapati Lahari</h1>
            <p class="tagline">Computer Science Graduate | AI Acceleration Enthusiast</p>
            
            <div class="nav-links">
                <a href="mailto:lahari1803ks@gmail.com" class="nav-link">
                    <img src="mail.png" alt="gmail" class="nav-icon" />
                    <span>Email</span>
                </a>
                <a href="blog.html" class="nav-link">
                    <img src="blog.png" alt="Blog" class="nav-icon" />
                    <span>Blog</span>
                </a>
                <a href="https://github.com/LAHARI2003" class="nav-link" target="_blank">
                    <img src="github.jpg" alt="github" class="nav-icon" />
                    <span>GitHub</span>
                </a>
            </div>
        </header>

        <section class="about-section">
            <h2>About Me</h2>
            <p>Iâ€™m <strong>Kommalapati Lahari</strong>, an IIT Patna Computer Science graduate.</p> 
            
            <p>
                My research focuses on developing efficient and sustainable AI accelerators by jointly optimizing algorithms
                and architectures. I see a paradigm shift from large-scale LLMs toward <strong>Edge Language Models (ELMs)</strong>
                optimized for batch size = 1 and memory-constrained deployment, enabling what I call <strong>deep edge intelligence</strong>
                through localized, adaptive inference.
            </p>

            <p>
                I am actively exploring transformers and post-transformer architectures, particularly <strong>state-space hybrids like the
                Mamba series</strong>, which offer linear-time inference with transformer-level accuracy. I am driven by recent results 
                demonstrating the tangible potential of this paradigm for modalities like voice, where linear complexity scaling becomes critical.
            </p>

            <p>
                Building on this, my work involves <strong>Neural Architecture Search (NAS)</strong> and multi-dimensional model reduction through
                quantization, pruning, and sparsity to design architectures tailored for edge-level latency and power constraints.
                The guiding lens for this exploration is the <strong>Roofline model</strong>, which highlights how edge systems are predominantly
                memory-bound rather than compute-bound.
            </p>
            
            <p>
                Instead of maximizing arithmetic throughput, my research targets memory access efficiency and digital <strong>in-memory computing
                paradigms</strong> that retain data locality while sustaining performance. Ultimately, I envision a multi-context edge AI framework, 
                where compression-aware models power emerging applications in physical AI, robotics, and humanoid intelligence.
            </p>

            <p>
                I see agentic AI frameworks as the enabler of this shift, where generative systems guide architectural exploration dynamically rather 
                than through traditional static optimization. At its core, my research strives for sustainability through efficiency, aligning
                closely with the vision of energy-conscious computation.
            </p>
        </section>

        <section class="pubs-section">
            <h2>Research Publications</h2>
            <div class="pub-grid">
                <div class="pub-item">
                    <div class="pub-title">Classification of Driving Styles based on Longitudinal and Lateral Behavior at Exit Ramp Terminals</div>
                    <div class="pub-venue">Transportation Research Board (TRB) Annual Meeting 2025</div>
                    <div class="pub-links">Documentation: <a href="https://drive.google.com/file/d/19-ysAjo7rzFCUO0e0yvFXroGFh5o_q-T/view?usp=sharing" target="_blank" rel="noopener noreferrer">Acceptance Letter</a> | <a href="https://drive.google.com/file/d/1s2zLfvCQIBFVV5fxgzjLjgXjGnv6RdUv/view?usp=sharing" target="_blank" rel="noopener noreferrer">Full Paper</a></div>
                </div>
                <div class="pub-item">
                    <div class="pub-title">Autonomous Smart Contract Hardening: The Fusion of LLMs and Invariant-Guided Security Repair</div>
                    <div class="pub-venue">Foundations of Software Engineering (FSE) Conference 2026 (Under Review)</div>
                    <div class="pub-links">Documentation: <a href="https://drive.google.com/file/d/1WHfOLI-5aTAJM-4YtiNmkjzrcO96xL_8/view?usp=sharing" target="_blank" rel="noopener noreferrer">Paper Draft</a></div>
                </div>
            </div>
        </section>
    </div>
</body>
</html>
