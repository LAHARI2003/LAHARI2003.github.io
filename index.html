<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kommalapati Lahari</title>
    <link rel="stylesheet" href="styles.css">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600&display=swap" rel="stylesheet">
</head>
<body>
    <div class="container">
        <div class="content-box" style="text-align:center;">
            <h1 class="name">Kommalapati Lahari</h1>
            <div class="nav-links" style="margin-top:32px;">
                <a href="mailto:lahari1803ks@gmail.com" class="nav-link nav-with-icon">
                    <img src="mail.png" alt="gmail" class="nav-icon" />
                    <span>gmail</span>
                </a>
                <a href="blog.html" class="nav-link nav-with-icon">
                    <img src="blog.png" alt="Blog" class="nav-icon" />
                    <span>Blog</span>
                </a>
                <a href="https://github.com/LAHARI2003" class="nav-link nav-with-icon" target="_blank">
                    <img src="github.jpg" alt="github" class="nav-icon" />
                    <span>github</span>
                </a>
            </div>
            <section class="about-section">
                <h2>About Me</h2>
                <p>I knew I wanted to pursue a career in the AI domain, as research had always appealed to me—particularly the process of understanding systems at their most fundamental level and uncovering new possibilities. Throughout my internship, I have been proactive in expressing my interests and career aspirations to my mentor and manager, consistently seeking their guidance on which research areas to explore. This exploration led me to delve into AI accelerators and their architectures, where I studied the current state of the art, such as NVIDIA's Blackwell and AMD's MI350X.</p>
                <p>I was particularly intrigued by Language Processing Units (LPUs), especially after learning about the Kimi 2 model achieving 1 trillion parameters with 18x faster inference compared to existing hardware. Understanding the mechanisms behind TruePoint numerics and precise quantization, tailored to specific operations, revealed multiple layers of optimization available not only algorithmically but also at the hardware level. This significantly broadened my perspective on the substantial research potential in hardware abstraction for efficient inference.</p>
                <p>Examining the architectural differences between AI accelerators and traditional GPUs deepened my understanding further. The SIMT/SIMD execution models in NVIDIA GPUs, systolic architectures in TPUs, and SRAM‑centric deterministic pipeline architectures in LPUs each represent distinct approaches to AI workload optimization. These design choices directly affect computational capabilities, reinforcing my interest in how hardware architecture influences AI performance and accessibility.</p>
                <p>This combination of hands‑on experience with hardware constraints and understanding of model architectures has shaped my research direction toward the intersection of hardware‑aware model design and efficient inference systems. I am drawn to work where algorithmic innovations meet architectural optimizations to push computational boundaries. The potential to contribute to both theoretical foundations and practical implementations of AI accelerators—specifically in making advanced AI capabilities more accessible and efficient—represents the research path I want to pursue.</p>
            </section>
        </div>
    </div>
</body>
</html>
